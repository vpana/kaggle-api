{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "starter-notebook-edsa-classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vpana/kaggle-api/blob/master/starter_notebook_edsa_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FTPkQmOAQSZ"
      },
      "source": [
        "## Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "Q5tgJ86nAQSb"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5fxo4OoAQSk"
      },
      "source": [
        "## Load in your data from kaggle.  \n",
        "By working in a kaggle kernel, you can access the data directly from the competition, as well as make your submission without downloading your output file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nL4PW1IsAQSl"
      },
      "source": [
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "trusted": true,
        "id": "qvIFLvLAAQSs"
      },
      "source": [
        "train.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lgr8Gc7TAQSt",
        "outputId": "637b4d96-2854-4cf8-94f2-68cf4f41e0e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "train.sentiment.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    8530\n",
              " 2    3640\n",
              " 0    2353\n",
              "-1    1296\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IElv9NfHAQS0",
        "outputId": "bc2310aa-074d-435e-89e7-c23b5ac48f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
              "      <td>625221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
              "      <td>126103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
              "      <td>698562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
              "      <td>573736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
              "      <td>466954</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                            message  tweetid\n",
              "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
              "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
              "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
              "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
              "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMsrBeeoAQS6"
      },
      "source": [
        "## Splitting out the X variable from the target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yJbdWAJGAQS7"
      },
      "source": [
        "y = train['sentiment']\n",
        "X = train['message']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aB3HSKdzAQTA"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# init stemmer\n",
        "porter_stemmer=PorterStemmer()\n",
        "\n",
        "def my_cool_preprocessor(text):\n",
        "    \n",
        "    text=text.lower() \n",
        "    text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
        "    text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
        "    \n",
        "    # stem words\n",
        "    words=re.split(\"\\\\s+\",text)\n",
        "    stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
        "    return ' '.join(stemmed_words)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2clOJ4mMAQTG"
      },
      "source": [
        "def my_tokenizer(text):\n",
        "    # create a space between special characters \n",
        "    text=re.sub(\"(\\\\W)\",\" \\\\1 \",text)\n",
        "\n",
        "    # split based on whitespace\n",
        "    return re.split(\"\\\\s+\",text)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1kCqWbMAQTN"
      },
      "source": [
        "## Turning text into something your model can read"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jvdPtyidAQTP",
        "outputId": "ffc2a59c-f8e1-4900-ed91-05bce8e927ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1,2),tokenizer=my_tokenizer, min_df=2,max_df=0.70,analyzer='word',smooth_idf=False, preprocessor=my_cool_preprocessor,stop_words=\"english\")\n",
        "X_vectorized = vectorizer.fit_transform(X)\n",
        ", \n",
        "#stop_words=\"english\",max_df=0.85, preprocessor=my_cool_preprocessor,\"all\",\"in\",\"the\",\"is\",\"and\"preprocessor=my_cool_preprocessor"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dPbKxg-GAQTW"
      },
      "source": [
        "#vectorizer.vocabulary_\n",
        "#vectorizer.stop_words_"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF6BThD4AQTc"
      },
      "source": [
        "## Splitting the training data into a training and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D5JS50XOAQTe"
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(X_vectorized,y,test_size=0.25,shuffle=True, random_state=25)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxpo5CNmAQTj"
      },
      "source": [
        "## Training the model and evaluating using the validation set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sBJX5m5IAQTl"
      },
      "source": [
        "lsvc = LinearSVC()\n",
        "lsvc.fit(X_train, y_train)\n",
        "lsvc_pred = lsvc.predict(X_val)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtIsIxE2AQTr"
      },
      "source": [
        "## Checking the performance of our model on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EiOaX17ZAQTs",
        "outputId": "ce104203-bfe6-4510-bd04-fa036012bee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_score(y_val, lsvc_pred, average=\"macro\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6472371554942042"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "F_snRivYAQT5",
        "outputId": "c2d1fdeb-5370-4056-c2a9-ddde8aaf45c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.classification_report(y_val, lsvc_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.70      0.39      0.50       247\n",
            "           0       0.60      0.45      0.52       466\n",
            "           1       0.76      0.87      0.81      1749\n",
            "           2       0.76      0.75      0.75       702\n",
            "\n",
            "    accuracy                           0.74      3164\n",
            "   macro avg       0.71      0.62      0.65      3164\n",
            "weighted avg       0.73      0.74      0.73      3164\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP8-vhx1AQUC"
      },
      "source": [
        "## Getting our test set ready "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xob42olEAQUC"
      },
      "source": [
        "testx = test['message']\n",
        "test_vect = vectorizer.transform(testx)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RN71dNrAQUK"
      },
      "source": [
        "## Making predictions on the test set and adding a sentiment column to our original test df"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g9BZeE2iAQUL"
      },
      "source": [
        "y_pred = lsvc.predict(test_vect)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "682i0KobAQUW"
      },
      "source": [
        "test['sentiment'] = y_pred"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wIhzrLDKAQUi",
        "outputId": "c9e500da-3a20-4dcb-a8f5-7782cfb27fc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message</th>\n",
              "      <th>tweetid</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Europe will now be looking to China to make su...</td>\n",
              "      <td>169760</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Combine this with the polling of staffers re c...</td>\n",
              "      <td>35326</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The scary, unimpeachable evidence that climate...</td>\n",
              "      <td>224985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
              "      <td>476263</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
              "      <td>872928</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             message  tweetid  sentiment\n",
              "0  Europe will now be looking to China to make su...   169760          1\n",
              "1  Combine this with the polling of staffers re c...    35326          1\n",
              "2  The scary, unimpeachable evidence that climate...   224985          1\n",
              "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263          1\n",
              "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltw_F7qDAQUo"
      },
      "source": [
        "## Creating an output csv for submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xVYgwY7IAQUp"
      },
      "source": [
        "test[['tweetid','sentiment']].to_csv('testsubmission_8.csv', index=False)"
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}